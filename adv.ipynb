{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgGOD1UIG1QL"
      },
      "source": [
        "SPDX-FileCopyrightText: 2025 Yoshitaka Hirata\n",
        "\n",
        "SPDX-License-Identifier: BSD-3-Clause\n",
        "\n",
        "This code was created as part of an assignment for the Advanced Vision course in graduate school.\n",
        "Redistribution and use are permitted under the terms of the BSD 3-Clause License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25CaEtygHtvC"
      },
      "source": [
        "# 必要なライブラリ等をインポートと環境設定\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YefefI_dXYVs"
      },
      "outputs": [],
      "source": [
        "!pip -q install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SGfYt6AWXZ_o"
      },
      "outputs": [],
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtOq6LTXeHUY",
        "outputId": "5bbd7ccf-376c-4a82-9d3a-dee7bc2395d6"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5fFbLiZeXbmd"
      },
      "outputs": [],
      "source": [
        "#モデルの再現性のために乱数のシードを固定\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-LGHIsfH9QR"
      },
      "source": [
        "# CNN構築"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mNUQBXxYPBh",
        "outputId": "4343c3fb-7aef-4351-a5cd-0fa112be44b5"
      },
      "outputs": [],
      "source": [
        "class OriginModel(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        # 5x5 Conv(6), pad=2\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        # 2x2 MaxPool, stride=2\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # 5x5 Conv(16), pad=0\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=0)\n",
        "        # 2x2 MaxPool, stride=2\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # 16 * 5 * 5 = 400\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "        # 活性化関数\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.act(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)     # 平坦化\n",
        "        x = self.act(self.fc1(x))   # FC(120)\n",
        "        x = self.act(self.fc2(x))   # FC(84)\n",
        "        x = self.fc3(x)             # FC(10)\n",
        "        return x\n",
        "\n",
        "model = OriginModel().to(device)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sxHzHvsQYRuI"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()#交差エントロピー\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "P6gQBMNMYS5V"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    loss_sum, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for img, label in loader:\n",
        "        img = img.to(device, non_blocking=True)\n",
        "        label = label.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(img)\n",
        "        loss = criterion(logits, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_sum += loss.item() * img.size(0)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += (pred == label).sum().item()\n",
        "        total += img.size(0)\n",
        "\n",
        "    return loss_sum / total, correct / total\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    loss_sum, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for img, label in loader:\n",
        "        img = img.to(device, non_blocking=True)\n",
        "        label = label.to(device, non_blocking=True)\n",
        "\n",
        "        logits = model(img)\n",
        "        loss = criterion(logits, label)\n",
        "\n",
        "        loss_sum += loss.item() * img.size(0)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += (pred == label).sum().item()\n",
        "        total += img.size(0)\n",
        "\n",
        "    return loss_sum / total, correct / total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWZghJ0cC8dw"
      },
      "source": [
        "# 性能評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR2QbQuqDCbM"
      },
      "source": [
        "## MNISTデータセットダウンロードと前処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywuAEHERXd8T",
        "outputId": "9160ee7d-033a-4834-cfb5-1b114964d45a"
      },
      "outputs": [],
      "source": [
        "# MNISTの平均・標準偏差\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# train / test を両方DL\n",
        "train_full = datasets.MNIST(root=\"./data\", train=True,  download=True, transform=transform)  # 60000\n",
        "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)  # 10000\n",
        "\n",
        "print(\"train_full:\", len(train_full), \"test_ds:\", len(test_ds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BLZCUuDXf2N",
        "outputId": "895d9e2c-55c2-4d3e-93a1-ceb9a9f97a40"
      },
      "outputs": [],
      "source": [
        "# 元の訓練データをtrain:val = 8:2に分割\n",
        "train_len = int(len(train_full) * 0.8)  # 48,000\n",
        "val_len   = len(train_full) - train_len  # 12,000\n",
        "\n",
        "g = torch.Generator().manual_seed(42)\n",
        "\n",
        "train_ds, val_ds = random_split(\n",
        "    train_full,\n",
        "    [train_len, val_len],\n",
        "    generator=g\n",
        ")\n",
        "\n",
        "print(\"train / val:\", len(train_ds), len(val_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "l-aALITPYL9m"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z9fh9_wDN09"
      },
      "source": [
        "## 学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsPDWrD9YUsk",
        "outputId": "b43cf57b-a0dc-4542-9ab0-28dc2f22b192"
      },
      "outputs": [],
      "source": [
        "#学習回数\n",
        "EPOCHS = 5\n",
        "\n",
        "train_losses, train_accs = [], []\n",
        "val_losses, val_accs     = [], []\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "    va_loss, va_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    train_losses.append(tr_loss); train_accs.append(tr_acc)\n",
        "    val_losses.append(va_loss);   val_accs.append(va_acc)\n",
        "\n",
        "    print(f\"[Epoch {epoch:02d}] \"\n",
        "          f\"train_loss={tr_loss:.4f}, train_acc={tr_acc:.4f} | \"\n",
        "          f\"val_loss={va_loss:.4f}, val_acc={va_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "vZ_sGPV1YV1f",
        "outputId": "2332b800-0fc2-4a91-d4a8-e4debb5e3a77"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, EPOCHS + 1)\n",
        "\n",
        "# 精度\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_accs, label=\"train_acc\")\n",
        "plt.plot(epochs, val_accs, label=\"val_acc\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xticks(epochs)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 損失\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_losses, label=\"train_loss\")\n",
        "plt.plot(epochs, val_losses, label=\"val_loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xticks(epochs)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toR6GESjID0k"
      },
      "source": [
        "## モデルテスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh6DVolRYW0G",
        "outputId": "72e65ec3-7702-49e7-d7dd-d91d3d62b9fe"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "print(f\"TEST: loss={test_loss:.4f}, acc={test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "QflWxCv7YYIf",
        "outputId": "e872fcfa-3175-4b34-e676-6ab3c33115d8"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def get_all_preds(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    for img, label in loader:\n",
        "        img = img.to(device, non_blocking=True)\n",
        "        logits = model(img)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "        all_labels.append(label.numpy())\n",
        "    return np.concatenate(all_preds), np.concatenate(all_labels)\n",
        "\n",
        "preds, labels = get_all_preds(model, test_loader, device)\n",
        "\n",
        "cm = confusion_matrix(labels, preds, labels=list(range(10)))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(range(10)))\n",
        "disp.plot(values_format=\"d\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "AhSJoS3xruh5",
        "outputId": "c84d665f-9259-46cd-98f0-4fbf10889de4"
      },
      "outputs": [],
      "source": [
        "# 成功例・失敗例の可視化\n",
        "\n",
        "# 結果を取得\n",
        "img_all, label_all = next(iter(DataLoader(\n",
        "    test_loader.dataset,\n",
        "    batch_size=len(test_loader.dataset),\n",
        "    shuffle=False\n",
        ")))\n",
        "img_all = img_all.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits_all = model(img_all)\n",
        "    preds_all = logits_all.argmax(dim=1).cpu()\n",
        "\n",
        "correct_idx = (preds_all == label_all).nonzero(as_tuple=True)[0]\n",
        "wrong_idx   = (preds_all != label_all).nonzero(as_tuple=True)[0]\n",
        "\n",
        "# 表示\n",
        "num_show = 3\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "\n",
        "# 成功例\n",
        "for i in range(num_show):\n",
        "    idx = correct_idx[i].item()\n",
        "    plt.subplot(2, num_show, i + 1)\n",
        "    img = img_all[idx].cpu().squeeze(0).numpy()\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.title(f\"True:{label_all[idx]} Pred:{preds_all[idx]}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# 失敗例\n",
        "for i in range(num_show):\n",
        "    idx = wrong_idx[i].item()\n",
        "    plt.subplot(2, num_show, num_show + i + 1)\n",
        "    img = img_all[idx].cpu().squeeze(0).numpy()\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.title(f\"True:{label_all[idx]} Pred:{preds_all[idx]}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Top: Correct predictions / Bottom: Wrong predictions\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
